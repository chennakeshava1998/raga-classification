Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

2019-12-07 07:22:46.581221: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-07 07:22:46.594156: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-12-07 07:22:46.595149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e834529c00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-12-07 07:22:46.595215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-12-07 07:22:46.596041: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Raga: kalyani 	 Number of Input files: 665
Raga: pantuvarali 	 Number of Input files: 377
Raga: kedaragaula 	 Number of Input files: 273
Raga: thodi 	 Number of Input files: 556
Raga: begada 	 Number of Input files: 615
Raga: bhairavi 	 Number of Input files: 567
Raga: mohana 	 Number of Input files: 436
Raga: sankarabharana 	 Number of Input files: 770
4259
4259
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 478, 638, 32)      896       
_________________________________________________________________
activation_1 (Activation)    (None, 478, 638, 32)      0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 119, 159, 32)      0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 117, 157, 32)      9248      
_________________________________________________________________
activation_2 (Activation)    (None, 117, 157, 32)      0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 29, 39, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 27, 37, 32)        9248      
_________________________________________________________________
activation_3 (Activation)    (None, 27, 37, 32)        0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 6, 9, 32)          0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 7, 32)          9248      
_________________________________________________________________
activation_4 (Activation)    (None, 4, 7, 32)          0         
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 2, 3, 32)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 192)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                6176      
_________________________________________________________________
activation_5 (Activation)    (None, 32)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056      
_________________________________________________________________
activation_6 (Activation)    (None, 32)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 264       
_________________________________________________________________
activation_7 (Activation)    (None, 8)                 0         
=================================================================
Total params: 36,136
Trainable params: 36,136
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/200
 - 80s - loss: 2.8020 - accuracy: 0.1578
Epoch 2/200
 - 79s - loss: 2.0682 - accuracy: 0.1785
Epoch 3/200
 - 79s - loss: 2.1514 - accuracy: 0.1750
Epoch 4/200
 - 82s - loss: 2.0449 - accuracy: 0.1772
Epoch 5/200
 - 81s - loss: 2.0402 - accuracy: 0.1778
Epoch 6/200
 - 81s - loss: 2.0403 - accuracy: 0.1778
Epoch 7/200
 - 79s - loss: 2.0394 - accuracy: 0.1778
Epoch 8/200
 - 79s - loss: 2.0380 - accuracy: 0.1778
Epoch 9/200
 - 80s - loss: 2.0388 - accuracy: 0.1778
Epoch 10/200
 - 79s - loss: 2.0400 - accuracy: 0.1778
Epoch 11/200
 - 81s - loss: 2.0375 - accuracy: 0.1778
Epoch 12/200
 - 81s - loss: 2.0383 - accuracy: 0.1778
Epoch 13/200
 - 82s - loss: 2.0389 - accuracy: 0.1778
Epoch 14/200
 - 81s - loss: 2.0388 - accuracy: 0.1778
Epoch 15/200
 - 81s - loss: 2.0389 - accuracy: 0.1778
Epoch 16/200
 - 79s - loss: 2.0384 - accuracy: 0.1778
Epoch 17/200
 - 81s - loss: 2.0382 - accuracy: 0.1778
Epoch 18/200
 - 77s - loss: 2.0385 - accuracy: 0.1778
Epoch 19/200
 - 77s - loss: 2.0383 - accuracy: 0.1778
Epoch 20/200
 - 82s - loss: 2.0374 - accuracy: 0.1778
Epoch 21/200
 - 77s - loss: 2.0380 - accuracy: 0.1778
Epoch 22/200
 - 79s - loss: 2.0378 - accuracy: 0.1778
Epoch 23/200
 - 78s - loss: 2.0394 - accuracy: 0.1778
Epoch 24/200
 - 78s - loss: 2.0377 - accuracy: 0.1778
Epoch 25/200
 - 78s - loss: 2.0389 - accuracy: 0.1778
Epoch 26/200
 - 79s - loss: 2.0379 - accuracy: 0.1778
Epoch 27/200
 - 78s - loss: 2.0382 - accuracy: 0.1778
Epoch 28/200
 - 79s - loss: 2.0387 - accuracy: 0.1778
Epoch 29/200
 - 80s - loss: 2.0390 - accuracy: 0.1778
Epoch 30/200
 - 81s - loss: 2.0389 - accuracy: 0.1778
Epoch 31/200
 - 79s - loss: 2.0386 - accuracy: 0.1778
Epoch 32/200
 - 82s - loss: 2.0382 - accuracy: 0.1778
Epoch 33/200
 - 80s - loss: 2.0384 - accuracy: 0.1778
Epoch 34/200
 - 79s - loss: 2.0378 - accuracy: 0.1778
Epoch 35/200
 - 80s - loss: 2.0386 - accuracy: 0.1778
Epoch 36/200
 - 83s - loss: 2.0380 - accuracy: 0.1778
Epoch 37/200
 - 81s - loss: 2.0383 - accuracy: 0.1778
Epoch 38/200
 - 81s - loss: 2.0376 - accuracy: 0.1778
Epoch 39/200
 - 82s - loss: 2.0376 - accuracy: 0.1778
Epoch 40/200
 - 80s - loss: 2.0376 - accuracy: 0.1778
Epoch 41/200
 - 80s - loss: 2.0382 - accuracy: 0.1778
Epoch 42/200
 - 80s - loss: 2.0374 - accuracy: 0.1778
Epoch 43/200
 - 80s - loss: 2.0375 - accuracy: 0.1778
Epoch 44/200
 - 79s - loss: 2.0379 - accuracy: 0.1778
Epoch 45/200
 - 78s - loss: 2.0371 - accuracy: 0.1778
Epoch 46/200
 - 79s - loss: 2.0373 - accuracy: 0.1778
Epoch 47/200
 - 80s - loss: 2.0373 - accuracy: 0.1778
Epoch 48/200
 - 80s - loss: 2.0373 - accuracy: 0.1778
Epoch 49/200
 - 82s - loss: 2.0376 - accuracy: 0.1778
Epoch 50/200
 - 80s - loss: 2.0386 - accuracy: 0.1778
Epoch 51/200
 - 80s - loss: 2.0373 - accuracy: 0.1778
Epoch 52/200
 - 79s - loss: 2.0382 - accuracy: 0.1778
Epoch 53/200
 - 80s - loss: 2.0379 - accuracy: 0.1778
Epoch 54/200
 - 81s - loss: 2.0377 - accuracy: 0.1778
Epoch 55/200
 - 81s - loss: 2.0378 - accuracy: 0.1778
Epoch 56/200
 - 80s - loss: 2.0383 - accuracy: 0.1778
Epoch 57/200
 - 82s - loss: 2.0373 - accuracy: 0.1778
Epoch 58/200
 - 79s - loss: 2.0379 - accuracy: 0.1778
Epoch 59/200
 - 79s - loss: 2.0375 - accuracy: 0.1778
Epoch 60/200
 - 78s - loss: 2.0383 - accuracy: 0.1778
Epoch 61/200
 - 79s - loss: 2.0372 - accuracy: 0.1778
Epoch 62/200
 - 81s - loss: 2.0375 - accuracy: 0.1778
Epoch 63/200
 - 80s - loss: 2.0373 - accuracy: 0.1778
Epoch 64/200
 - 79s - loss: 2.0377 - accuracy: 0.1778
Epoch 65/200
 - 79s - loss: 2.0370 - accuracy: 0.1778
Using TensorFlow backend.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

2019-12-07 09:31:54.433049: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-07 09:31:54.831866: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-12-07 09:31:54.832822: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5581264e8860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-12-07 09:31:54.832902: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-12-07 09:31:54.864283: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Raga: kalyani 	 Number of Input files: 665
Raga: pantuvarali 	 Number of Input files: 377
Raga: kedaragaula 	 Number of Input files: 273
Raga: thodi 	 Number of Input files: 556
Raga: begada 	 Number of Input files: 615
Raga: bhairavi 	 Number of Input files: 567
Raga: mohana 	 Number of Input files: 436
Raga: sankarabharana 	 Number of Input files: 770
4259
4259
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 478, 638, 32)      896       
_________________________________________________________________
activation_1 (Activation)    (None, 478, 638, 32)      0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 119, 159, 32)      0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 117, 157, 64)      18496     
_________________________________________________________________
activation_2 (Activation)    (None, 117, 157, 64)      0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 29, 39, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 27, 37, 128)       73856     
_________________________________________________________________
activation_3 (Activation)    (None, 27, 37, 128)       0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 6, 9, 128)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 7, 128)         147584    
_________________________________________________________________
activation_4 (Activation)    (None, 4, 7, 128)         0         
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 2, 3, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 768)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                24608     
_________________________________________________________________
activation_5 (Activation)    (None, 32)                0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 8)                 264       
_________________________________________________________________
activation_6 (Activation)    (None, 8)                 0         
=================================================================
Total params: 265,704
Trainable params: 265,704
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/200
 - 103s - loss: 4.3211 - accuracy: 0.1584
Epoch 2/200
 - 99s - loss: 2.0657 - accuracy: 0.1778
Epoch 3/200
 - 97s - loss: 2.0575 - accuracy: 0.1778
Epoch 4/200
 - 99s - loss: 2.0517 - accuracy: 0.1778
Epoch 5/200
 - 99s - loss: 2.0473 - accuracy: 0.1778
